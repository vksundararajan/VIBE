<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on Buffor // Books</title><link>https://buffor.lol/tags/ai/</link><description>Recent content in AI on Buffor // Books</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 16 May 2025 08:55:40 -0400</lastBuildDate><atom:link href="https://buffor.lol/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Behind the Prompts: What I Learned from Engineering LLM Prompts</title><link>https://buffor.lol/blog/behind-the-prompts-what-i-learned-from-engineering-llm-prompts/</link><pubDate>Fri, 16 May 2025 08:55:40 -0400</pubDate><guid>https://buffor.lol/blog/behind-the-prompts-what-i-learned-from-engineering-llm-prompts/</guid><description>&lt;p>Over the last 2 days, I’ve dived deep into &lt;mark>Prompt Engineering&lt;/mark> — not the surface-level prompt crafting, but the core architecture of how LLMs interpret, generate, and optimise responses based on prompt structure and configuration.&lt;/p>
&lt;p>What started as a casual exploration through &lt;strong>Google’s Prompt Engineering Essentials&lt;/strong> turned into an unexpectedly technical journey that bridged NLP design, token sampling, inference configuration, and agent-based reasoning.&lt;/p>
&lt;p>Let’s break it down.&lt;/p>
&lt;h2 id="llms-are-not-magical--theyre-token-predictors">LLMs Are Not Magical — They&amp;rsquo;re Token Predictors&lt;/h2>
&lt;p>Large Language Models, whether GPT, Gemini, Claude, or Llama, are not creative writers — they are statistical machines that &lt;strong>predict the next token given the previous context&lt;/strong>. That’s all.&lt;/p></description></item></channel></rss>