<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>KT on Buffor // Blog</title><link>https://vksundararajan.github.io/buffor.lol/tags/kt/</link><description>Recent content in KT on Buffor // Blog</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 16 May 2025 08:55:40 -0400</lastBuildDate><atom:link href="https://vksundararajan.github.io/buffor.lol/tags/kt/index.xml" rel="self" type="application/rss+xml"/><item><title>Behind the Prompts: What I Learned from Engineering LLM Prompts</title><link>https://vksundararajan.github.io/buffor.lol/blog/behind-the-prompts-what-i-learned-from-engineering-llm-prompts/</link><pubDate>Fri, 16 May 2025 08:55:40 -0400</pubDate><guid>https://vksundararajan.github.io/buffor.lol/blog/behind-the-prompts-what-i-learned-from-engineering-llm-prompts/</guid><description>&lt;p>Over the last 2 days, I’ve dived deep into &lt;mark>Prompt Engineering&lt;/mark> — not the surface-level prompt crafting, but the core architecture of how LLMs interpret, generate, and optimise responses based on prompt structure and configuration.&lt;/p>
&lt;p>What started as a casual exploration through &lt;strong>Google’s Prompt Engineering Essentials&lt;/strong> turned into an unexpectedly technical journey that bridged NLP design, token sampling, inference configuration, and agent-based reasoning.&lt;/p>
&lt;p>Let’s break it down.&lt;/p>
&lt;h2 id="llms-are-not-magical--theyre-token-predictors">LLMs Are Not Magical — They&amp;rsquo;re Token Predictors&lt;/h2>
&lt;p>Large Language Models, whether GPT, Gemini, Claude, or Llama, are not creative writers — they are statistical machines that &lt;strong>predict the next token given the previous context&lt;/strong>. That’s all.&lt;/p></description></item><item><title>Beyond Bugs and Pipelines: Source Code Review Intelligence</title><link>https://vksundararajan.github.io/buffor.lol/blog/beyond-bugs-and-pipelines-source-code-review-intelligence/</link><pubDate>Sat, 03 May 2025 00:00:00 +0000</pubDate><guid>https://vksundararajan.github.io/buffor.lol/blog/beyond-bugs-and-pipelines-source-code-review-intelligence/</guid><description>&lt;p>In today’s software landscape, security is less about gates and more about gradients. It’s no longer enough to write secure code — we must think about how that code emerges, how it&amp;rsquo;s validated, and how it evolves.&lt;/p>
&lt;p>Over the past months, I’ve delved into both dimensions: the theory and execution of a Secure Software Development Life Cycle (S-SDLC), and the manual + automated art of Source Code Review. But the synergy between the two isn’t well documented.&lt;/p></description></item></channel></rss>